{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/haalcala/NYP-SDAI/blob/master/ITI105/project/Fraud_detection_harold_lr.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\" align=\"left\"/></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fraud detection using Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import io\n",
    "import os\n",
    "\n",
    "try:\n",
    "    os.mkdir(\"./tmp\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "external_files = [\n",
    "  {\n",
    "      \"url\":\"https://raw.githubusercontent.com/haalcala/NYP-SDAI/master/ITI105/project/ds_util.py\",\n",
    "      \"local_file\":\"ds_util.py\"\n",
    "  },\n",
    "  {\n",
    "      \"url\":\"https://raw.githubusercontent.com/haalcala/NYP-SDAI/master/ITI105/project/files/bs140513_032310.csv\",\n",
    "      \"local_file\":\"bs140513_032310.csv\"\n",
    "  },\n",
    "]\n",
    "\n",
    "for ext_file in external_files:\n",
    "  req = requests.get(ext_file[\"url\"])\n",
    "\n",
    "  print(ext_file[\"local_file\"], len(req.content))\n",
    "\n",
    "  f = open(\"./tmp/\" + ext_file[\"local_file\"],\"wb\")\n",
    "\n",
    "  f.write(req.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## load and prepare data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tmp.ds_util as util\n",
    "\n",
    "ds_util = util.DSUtil()\n",
    "ds_util.load_csv(\"./tmp/bs140513_032310.csv\")\n",
    "\n",
    "# analyse data composition\n",
    "ds_util.blow_my_mind()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### drop columns not needed for calculations and get dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_util.drop_columns([\"customer\", \"zipMerchant\", \"zipcodeOri\"])\n",
    "\n",
    "df = ds_util.get_dummies()\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Stuffs                  \n",
    "\n",
    "### Environment initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#We need to import the k-NN Classifier from skleart.neighbors\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import numpy as np\n",
    "\n",
    "target_column = \"fraud\"\n",
    "\n",
    "y = df[target_column]\n",
    "\n",
    "X = df.drop(target_column, axis=1)\n",
    "\n",
    "sm = SMOTE(random_state=12)\n",
    "x_res, y_res = sm.fit_sample(X, y)\n",
    "print(y.value_counts(), np.bincount(y_res))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_res, y_res, train_size=0.8, shuffle=True, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# lr_clf = LogisticRegression(solver='liblinear', random_state=42)\n",
    "lr_clf = LogisticRegression(solver='liblinear', random_state=42)\n",
    "\n",
    "y_pred = None\n",
    "\n",
    "def train_fn():\n",
    "    global lr_clf\n",
    "    \n",
    "    lr_clf.fit(X_train, y_train)\n",
    "\n",
    "ds_util.activity_wrapper(\"Training\", train_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_precision_recall_vs_threshold(precisions, recalls, thresholds):\n",
    "    plt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\", linewidth=2)\n",
    "    plt.plot(thresholds, recalls[:-1], \"g-\", label=\"Recall\", linewidth=2)\n",
    "    plt.legend(loc=\"center right\", fontsize=16) \n",
    "    plt.xlabel(\"Threshold\", fontsize=16)        \n",
    "    plt.grid(True)                                           \n",
    "\n",
    "def test_fn():\n",
    "    global y_pred\n",
    "    \n",
    "    y_pred = lr_clf.predict(X_test) \n",
    "    \n",
    "    print(\"accuracy_score:\", accuracy_score(y_test, y_pred))\n",
    "    \n",
    "    print(\"cross_val_score:\", cross_val_score(lr_clf, X_train, y_train, cv=3, scoring=\"accuracy\"))\n",
    "    \n",
    "    y_train_pred = cross_val_predict(lr_clf, X_train, y_train, cv=3)\n",
    "    \n",
    "    print(\"confusion_matrix\", confusion_matrix(y_train, y_train_pred))\n",
    "    \n",
    "#     y_train_perfect_predictions = y_train\n",
    "    \n",
    "#     print(\"confusion_matrix\", confusion_matrix(y_train, y_train_perfect_predictions))\n",
    "    \n",
    "    print(\"recall_score:\", recall_score(y_train, y_train_pred, pos_label=0))\n",
    "    print(\"precision_score:\", precision_score(y_train, y_train_pred, pos_label=0))\n",
    "    print(\"f1_score:\",f1_score(y_train, y_train_pred, pos_label=0))\n",
    "    \n",
    "    print(\"classification_report:\", classification_report(y_train, y_train_pred))\n",
    "    \n",
    "    y_scores = cross_val_predict(lr_clf, X_train, y_train, cv=3, method=\"decision_function\")\n",
    "    \n",
    "    print(y_scores)\n",
    "    \n",
    "    precisions, recalls, thresholds = precision_recall_curve(y_train, y_scores)\n",
    "    \n",
    "    plt.figure(figsize=(8, 4))                      \n",
    "    plot_precision_recall_vs_threshold(precisions, recalls, thresholds)\n",
    "    \n",
    "    plt.show()\n",
    "        \n",
    "ds_util.activity_wrapper(\"Testing\", test_fn)\n",
    "\n",
    "print(\"All done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_decision_regions(X,y,classifier,test_idx=None,resolution=0.02):\n",
    "    \n",
    "    # Initialise the marker types and colors\n",
    "    markers = ('s','x','o','^','v')\n",
    "    colors = ('red','blue','lightgreen','gray','cyan')\n",
    "    color_Map = ListedColormap(colors[:len(np.unique(y))]) #we take the color mapping correspoding to the \n",
    "                                                            #amount of classes in the target data\n",
    "    \n",
    "    # Parameters for the graph and decision surface\n",
    "    x1_min = X[:,0].min() - 1\n",
    "    x1_max = X[:,0].max() + 1\n",
    "    x2_min = X[:,1].min() - 1\n",
    "    x2_max = X[:,1].max() + 1\n",
    "    xx1, xx2 = np.meshgrid(np.arange(x1_min,x1_max,resolution),\n",
    "                           np.arange(x2_min,x2_max,resolution))\n",
    "    \n",
    "    Z = classifier.predict(np.array([xx1.ravel(),xx2.ravel()]).T)\n",
    "    Z = Z.reshape(xx1.shape)\n",
    "    \n",
    "    plt.contour(xx1,xx2,Z,alpha=0.4,cmap = color_Map)\n",
    "    plt.xlim(xx1.min(),xx1.max())\n",
    "    plt.ylim(xx2.min(),xx2.max())\n",
    "    \n",
    "    # Plot samples\n",
    "    X_test, Y_test = X[test_idx,:], y[test_idx]\n",
    "    \n",
    "    for idx, cl in enumerate(np.unique(y)):\n",
    "        plt.scatter(x = X[y == cl, 0], y = X[y == cl, 1],\n",
    "                    alpha = 0.8, c = color_Map(idx),\n",
    "                    marker = markers[idx], label = cl\n",
    "                   )\n",
    "        \n",
    "import pandas as pd\n",
    "\n",
    "# def test_params():\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "C_param_range = [0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]\n",
    "\n",
    "sepal_acc_table = pd.DataFrame(columns = [\"C_param\", \"Training Time\", \"Accuracy\", \"X-Val\"])\n",
    "sepal_acc_table[\"C_param\"] = C_param_range\n",
    "\n",
    "X_combined = np.vstack((X_train,X_test))\n",
    "Y_combined = np.hstack((y_train, y_test))\n",
    "\n",
    "j = 0\n",
    "for i in C_param_range:\n",
    "    print(\"i:\",i)\n",
    "    # Apply logistic regression model to training data\n",
    "    lr = LogisticRegression(solver='saga', max_iter=1000, n_jobs=4, C=i, random_state=42)\n",
    "\n",
    "    y_pred = None\n",
    "\n",
    "    def train_fn():\n",
    "        global lr\n",
    "        \n",
    "        lr.fit(X_train, y_train)\n",
    "\n",
    "    elapsed = ds_util.activity_wrapper(\"Training\", train_fn)\n",
    "    \n",
    "    y_pred = lr.predict(X_test) \n",
    "\n",
    "    print(\"elapsed:\", elapsed)\n",
    "\n",
    "    accuracy_result = accuracy_score(y_test, y_pred)\n",
    "    cross_val_result = cross_val_score(lr, X_train, y_train, cv=3, scoring=\"accuracy\")\n",
    "    \n",
    "    print(\"accuracy_score:\", accuracy_result)\n",
    "    print(\"cross_val_score:\", cross_val_result)\n",
    "    \n",
    "    # Saving accuracy score in table\n",
    "    sepal_acc_table.iloc[j,1] = str(elapsed.total_seconds()) + \" secs\"\n",
    "    sepal_acc_table.iloc[j,2] = str(accuracy_result)\n",
    "    sepal_acc_table.iloc[j,3] = str(cross_val_result)\n",
    "    j += 1\n",
    "    \n",
    "    # Printing decision regions\n",
    "    # plt.subplot(3,2,j)\n",
    "    # plt.subplots_adjust(hspace = 0.4)\n",
    "    # plot_decision_regions(X = X_combined\n",
    "    #                   , y = Y_combined\n",
    "    #                   , classifier = lr\n",
    "    #                   , test_idx = range(105,150))\n",
    "    # plt.xlabel('Sepal length')\n",
    "    # plt.ylabel('Sepal width')\n",
    "    # plt.title('C = %s'%i)\n",
    "\n",
    "    print(\"------------------------------------\")\n",
    "\n",
    "# test_params()\n",
    "\n",
    "sepal_acc_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
